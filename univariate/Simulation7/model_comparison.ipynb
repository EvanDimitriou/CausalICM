{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import GPy\n",
    "from functions.data_simulation import data_simulation7\n",
    "from functions.model_training import ICM\n",
    "\n",
    "\n",
    "from sklearn.cluster import SpectralClustering as sc\n",
    "import numpy.random as rand\n",
    "from numpy.linalg import norm as dist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from functools import partial\n",
    "from scipy.special import expit\n",
    "from sklearn.linear_model import Ridge as ridge\n",
    "from sklearn.linear_model import Lasso as lasso\n",
    "from sklearn.linear_model import LinearRegression as ols\n",
    "from sklearn.svm import SVR as kernel_svr\n",
    "from sklearn.svm import LinearSVR as lin_svr\n",
    "from sklearn.kernel_ridge import KernelRidge as kernel_ridge\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor as reg_tree\n",
    "from sklearn.ensemble import RandomForestRegressor as rfr\n",
    "from sklearn.ensemble import AdaBoostRegressor as ada_reg\n",
    "from sklearn.ensemble import GradientBoostingRegressor as gbr\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import copy\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "rmse = lambda x,y: np.power(mse(x,y), 0.5)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import rpy2.robjects as robjects\n",
    "import rpy2.robjects.numpy2ri as np2ri\n",
    "\n",
    "robjects.numpy2ri.activate()\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import GPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr_reg_parameter_pairs = [(rfr(),{#'max_depth':[None] + list(range(2,11,4)),\n",
    "                             'min_samples_leaf':list(range(1,11,3)), \n",
    "                             'n_estimators':[100, 200]})]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "linear_reg_parameter_pairs = []\n",
    "linear_reg_parameter_pairs.append((ridge(), {'alpha':np.logspace(-7, 7,8),\n",
    "                                             'tol':[1e-3]}))\n",
    "\n",
    "def get_best_model_from_gridcv(X, Y, reg_parameter_pairs, print_flag = False, verbose = 0):\n",
    "    val_errs = []\n",
    "    models = []\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2)\n",
    "    for reg, parameters in reg_parameter_pairs:\n",
    "        if print_flag:\n",
    "            print('trying ', str(reg)[:50])\n",
    "        model = GridSearchCV(reg, parameters, cv=2, refit=True, verbose=verbose, n_jobs = 10)\n",
    "        model.fit(X,Y)\n",
    "        val_errs.append(rmse(y_test, model.predict(x_test)))\n",
    "#         if print_flag:\n",
    "#             print('trying ' + str(reg)[:60], val_errs[-1])\n",
    "        models.append(copy.deepcopy(model.best_estimator_))\n",
    "    min_ind = val_errs.index(min(val_errs))\n",
    "    if verbose != 0:\n",
    "        print(str(models[min_ind]), 'val rmse:{}'.format(val_errs[min_ind]))\n",
    "    return copy.deepcopy(models[min_ind])\n",
    "\n",
    "def run_methodGP(X_rct, Y_rct, T_rct, X_obs, Y_obs, T_obs, _internal_X_not_rct):\n",
    "    assert(X_rct.shape[0] == Y_rct.shape[0])\n",
    "    assert(T_rct.shape[0] == Y_rct.shape[0])\n",
    "    assert(X_obs.shape[0] == Y_obs.shape[0])\n",
    "    assert(T_obs.shape[0] == Y_obs.shape[0])\n",
    "    \n",
    "    # Naive GP trained on the observational data\n",
    "    \n",
    "    # Control\n",
    "    import GPy\n",
    "    kern = GPy.kern.RBF(input_dim=1, variance=1., lengthscale=1.)\n",
    "    f0_gp_model = GPy.models.GPRegression(np.vstack(X_obs[T_obs==0]), np.vstack(Y_obs[T_obs==0]), kern)\n",
    "    f0_gp_model.optimize()\n",
    "\n",
    "    # Treated\n",
    "    kern = GPy.kern.RBF(input_dim=1, variance=1., lengthscale=1.)\n",
    "    f1_gp_model = GPy.models.GPRegression(np.vstack(X_obs[T_obs==1]),\n",
    "                                          np.vstack(Y_obs[T_obs==1]),\n",
    "                                          kern)\n",
    "    f1_gp_model.optimize()\n",
    "\n",
    "    # Predict the expectation\n",
    "    omega_rct_pred = f1_gp_model.predict(np.vstack(X_rct))[0] - f0_gp_model.predict(np.vstack(X_rct))[0]\n",
    "    omega_obs_pred = f1_gp_model.predict(np.vstack(X_obs))[0] - f0_gp_model.predict(np.vstack(X_obs))[0]\n",
    "    omega_all_pred = f1_gp_model.predict(np.vstack(X_all))[0] - f0_gp_model.predict(np.vstack(X_all))[0]\n",
    "    omega_not_rct_pred = f1_gp_model.predict(np.vstack(_internal_X_not_rct))[0] - f0_gp_model.predict(np.vstack(_internal_X_not_rct))[0]\n",
    "    \n",
    "    \n",
    "    _propensity_rct = np.sum(T_rct)/T_rct.shape[0]\n",
    "    cate_rct_est = ite_adjusted_outcome(Y_rct, T_rct, _propensity=_propensity_rct) # CHECKED\n",
    "\n",
    "    # omega  and cate_rct_est should both have a shape (n_rct,)\n",
    "    #assert(cate_rct_est.shape == omega_rct_pred.shape)\n",
    "    eta_rct_est = np.vstack(cate_rct_est) - np.vstack(omega_rct_pred)\n",
    "    #assert(len(eta_rct_est.shape) == 1)\n",
    "    \n",
    "    best_eta_est_linear = get_best_model_from_gridcv(X_rct.reshape(-1,1), eta_rct_est, linear_reg_parameter_pairs)\n",
    "    \n",
    "    return copy.deepcopy(best_eta_est_linear), omega_obs_pred, omega_not_rct_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_naiveGP_exp = np.zeros((100))\n",
    "rmse_naiveGP_obs = np.zeros((100))\n",
    "rmse_KallusGP = np.zeros((100))\n",
    "rmse_ICM = np.zeros((100))\n",
    "\n",
    "bias_naiveGP_exp = np.zeros((100))\n",
    "bias_naiveGP_obs = np.zeros((100))\n",
    "bias_KallusGP = np.zeros((100))\n",
    "bias_ICM = np.zeros((100))\n",
    "\n",
    "var_naiveGP_exp = np.zeros((100))\n",
    "var_naiveGP_obs = np.zeros((100))\n",
    "var_KallusGP = np.zeros((100))\n",
    "var_ICM = np.zeros((100))\n",
    "\n",
    "best_rho = pd.read_csv('sim7_best_rho.csv').values[0]\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "    print(i+1)\n",
    "    data_exp, data_obs = data_simulation7(1000, beta0=-3.0, beta1=-3.0)\n",
    "    # Data preprocessing\n",
    "    X0_obs = data_obs[:,1][data_obs[:,2]==0]\n",
    "    X1_obs = data_obs[:,1][data_obs[:,2]==1]\n",
    "    Y0_obs = data_obs[:,3][data_obs[:,2]==0]\n",
    "    Y1_obs = data_obs[:,3][data_obs[:,2]==1]\n",
    "\n",
    "    X0_exp = data_exp[:,1][data_exp[:,2]==0]\n",
    "    X1_exp = data_exp[:,1][data_exp[:,2]==1]\n",
    "    Y0_exp = data_exp[:,3][data_exp[:,2]==0]\n",
    "    Y1_exp = data_exp[:,3][data_exp[:,2]==1]\n",
    "\n",
    "    test_data = np.arange(-2.0,2.04,0.04)\n",
    "\n",
    "    trueCATE = 1+test_data\n",
    "    \n",
    "    # Naive GP trained on the observational data\n",
    "    kern = GPy.kern.RBF(input_dim=1, variance=1., lengthscale=1.)\n",
    "    m0_obs1 = GPy.models.GPRegression(np.vstack(X0_obs),np.vstack(Y0_obs),kern)\n",
    "    m0_obs1.optimize()\n",
    "    kern = GPy.kern.RBF(input_dim=1, variance=1., lengthscale=1.)\n",
    "    m1_obs1 = GPy.models.GPRegression(np.vstack(X1_obs),np.vstack(Y1_obs),kern)\n",
    "    m1_obs1.optimize()\n",
    "    # Predict the expectation\n",
    "    mu0_obs1 = m0_obs1.predict(np.vstack(test_data))[0]\n",
    "    mu1_obs1 = m1_obs1.predict(np.vstack(test_data))[0]\n",
    "    # Derive CATE\n",
    "    naiveCATE_obs1 = mu1_obs1 - mu0_obs1\n",
    "    \n",
    "\n",
    "    # Naive GP trained on the experimental data\n",
    "    kern = GPy.kern.RBF(input_dim=1, variance=1., lengthscale=1.)\n",
    "    m0_exp1 = GPy.models.GPRegression(np.vstack(X0_exp),np.vstack(Y0_exp),kern)\n",
    "    m0_exp1.optimize()\n",
    "    kern = GPy.kern.RBF(input_dim=1, variance=1., lengthscale=1.)\n",
    "    m1_exp1 = GPy.models.GPRegression(np.vstack(X1_exp),np.vstack(Y1_exp),kern)\n",
    "    m1_exp1.optimize()\n",
    "    # Predict the expectation\n",
    "    mu0_exp1 = m0_exp1.predict(np.vstack(test_data))[0]\n",
    "    mu1_exp1 = m1_exp1.predict(np.vstack(test_data))[0]\n",
    "    # Derive CATE\n",
    "    naiveCATE_exp1 = mu1_exp1 - mu0_exp1\n",
    "\n",
    "    # Kallus GP\n",
    "    Y_all = np.r_[data_obs[:,3], data_exp[:,3]]\n",
    "    X_all = np.r_[data_obs[:,1], data_exp[:,1]]\n",
    "    T_all = np.r_[data_obs[:,2], data_exp[:,2]]\n",
    "    X_eval = test_data\n",
    "    _mean_outcome = np.mean(data_obs[:,3])\n",
    "    _propensity_all = np.sum(data_obs[:,2])/data_obs[:,2].shape[0]\n",
    "    def ite_adjusted_outcome(Y,T,_propensity, c = _mean_outcome):\n",
    "        assert(_propensity>0)\n",
    "        assert(_propensity<1)\n",
    "        assert(len(Y.shape) == 1)\n",
    "        assert(Y.shape == T.shape )\n",
    "        _ite = np.zeros(Y.shape)\n",
    "        _ite[T==1] =  (Y[T==1]- c)/_propensity\n",
    "        _ite[T==0] = -(Y[T==0] - c)/(1-_propensity)\n",
    "        return _ite\n",
    "\n",
    "\n",
    "    eta_2step_modelGP, omega_obs_pred_2stepGP, omega_eval_pred_2stepGP = run_methodGP(data_exp[:,1], data_exp[:,3], \n",
    "                                                                                      data_exp[:,2], data_obs[:,1], \n",
    "                                                                                      data_obs[:,3], data_obs[:,2], \n",
    "                                                                                      test_data)\n",
    "\n",
    "    tau_pred_eval_2stepGP = eta_2step_modelGP.predict(test_data.reshape(-1,1)) + omega_eval_pred_2stepGP\n",
    "\n",
    "\n",
    "    # ICM\n",
    "    m0, m1 = ICM(X_E = data_exp[:,1], X_O = data_obs[:,1], \n",
    "                 T_E = data_exp[:,2], T_O = data_obs[:,2], \n",
    "                 Y_E = data_exp[:,3], Y_O = data_obs[:,3],  \n",
    "                 r = 2, ID=1, AD=0, rho=0.8)\n",
    "    predY0_exp1 = m0.predict_noiseless(np.c_[np.vstack(test_data),np.ones(test_data.shape[0])*0])\n",
    "    predY1_exp1 = m1.predict_noiseless(np.c_[np.vstack(test_data),np.ones(test_data.shape[0])*0])\n",
    "    predCATE_exp1 = predY1_exp1[0] - predY0_exp1[0]\n",
    "\n",
    "\n",
    "\n",
    "    rmse_ICM[i] = mean_squared_error((predCATE_exp1), (trueCATE), squared = False)\n",
    "    rmse_KallusGP[i] = mean_squared_error((tau_pred_eval_2stepGP), trueCATE, squared = False)\n",
    "    rmse_naiveGP_exp[i] = mean_squared_error((naiveCATE_exp1), trueCATE, squared = False)\n",
    "    rmse_naiveGP_obs[i] = mean_squared_error((naiveCATE_obs1), trueCATE, squared = False)\n",
    "\n",
    "    bias_naiveGP_exp[i] = np.mean(naiveCATE_exp1 - trueCATE)\n",
    "    bias_naiveGP_obs[i] = np.mean(naiveCATE_obs1 - trueCATE)\n",
    "    bias_KallusGP[i] = np.mean(tau_pred_eval_2stepGP - trueCATE)\n",
    "    bias_ICM[i] = np.mean(predCATE_exp1 - trueCATE)\n",
    "\n",
    "    var_naiveGP_exp[i] = np.mean((naiveCATE_exp1 - np.mean(naiveCATE_exp1))**2)\n",
    "    var_naiveGP_obs[i] = np.mean((naiveCATE_obs1 - np.mean(naiveCATE_obs1))**2)\n",
    "    var_KallusGP[i] = np.mean((tau_pred_eval_2stepGP - np.mean(tau_pred_eval_2stepGP))**2)\n",
    "    var_ICM[i] = np.mean((predCATE_exp1 - np.mean(predCATE_exp1))**2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert NumPy arrays to pandas DataFrames\n",
    "sim7_modelComparison_RMSEs_df = pd.DataFrame(np.c_[rmse_naiveGP_exp, rmse_naiveGP_obs, rmse_KallusGP, rmse_ICM,\n",
    "                                                   bias_naiveGP_exp, bias_naiveGP_obs, bias_KallusGP, bias_ICM,\n",
    "                                                   var_naiveGP_exp, var_naiveGP_obs, var_KallusGP, var_ICM], \n",
    "                                                     columns=['RMSE_naiveGPexp', 'RMSE_naiveGPobs', 'RMSE_KallusGP', 'RMSE_ICM',\n",
    "                                                              'bias_naiveGPexp', 'bias_naiveGPobs', 'bias_KallusGP', 'bias_ICM',\n",
    "                                                              'var_naiveGPexp', 'var_naiveGPobs', 'var_KallusGP', 'var_ICM'])\n",
    "\n",
    "# Save data_exp1 to a CSV file\n",
    "sim7_modelComparison_RMSEs_df.to_csv('sim7_modelComparison.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
