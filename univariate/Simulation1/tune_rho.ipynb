{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate and plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/evangelosdimitriou/myGitRepo/multi-task-GPs-for-Treatment-Effect-Estimation-2/__pycache__/neurIPS/Simulation 1', '/Users/evangelosdimitriou/anaconda3/lib/python310.zip', '/Users/evangelosdimitriou/anaconda3/lib/python3.10', '/Users/evangelosdimitriou/anaconda3/lib/python3.10/lib-dynload', '', '/Users/evangelosdimitriou/anaconda3/lib/python3.10/site-packages', '/Users/evangelosdimitriou/anaconda3/lib/python3.10/site-packages/PyQt5_sip-12.11.0-py3.10-macosx-10.9-x86_64.egg', '/Users/evangelosdimitriou/anaconda3/lib/python3.10/site-packages/aeosa', '/Users/evangelosdimitriou/anaconda3/lib/python3.10/site-packages/mpmath-1.2.1-py3.10.egg', '/Users/evangelosdimitriou/myGitRepo/multi-task-GPs-for-Treatment-Effect-Estimation-2/__pycache__/']\n"
     ]
    }
   ],
   "source": [
    "from functions.data_simulation import data_simulation1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value= 1234\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np \n",
    "np.random.seed(seed_value)\n",
    "data_exp, data_obs = data_simulation1(1000, beta0=-3.0, beta1=-3.0)\n",
    "data_full = np.r_[data_exp, data_obs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model for the probability of participation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "# Logistic regression model for the probability of participating in the trial\n",
    "# S=1 is trial participation and S=0 is non participation \n",
    "logr = linear_model.LogisticRegression()\n",
    "logr.fit(data_full[:,1].reshape(-1,1),data_full[:,0])\n",
    "prob = logr.predict_proba(data_full[:,1].reshape(-1,1))\n",
    "prob_part = prob[:,1]\n",
    "prob_nonpart = prob[:,0]\n",
    "data_full = np.c_[data_full, 1/prob_part]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune $\\rho$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rho: 0.0\n",
      "Fold 1 WMSE: 2.303620005612282\n",
      "Fold 2 WMSE: 1.757081898533712\n",
      "Fold 3 WMSE: 2.937985525476398\n",
      "Fold 4 WMSE: 3.1018293092008213\n",
      "Fold 5 WMSE: 4.010006586650174\n",
      "Average WMSE for Rho 0.0: 2.8221046650946775\n",
      "Rho: 0.1\n",
      "Fold 1 WMSE: 3.41629522732743\n",
      "Fold 2 WMSE: 2.6943804034372567\n",
      "Fold 3 WMSE: 3.7533431167751816\n",
      "Fold 4 WMSE: 2.2858201413963726\n",
      "Fold 5 WMSE: 1.873758519426712\n",
      "Average WMSE for Rho 0.1: 2.804719481672591\n",
      "Rho: 0.2\n",
      "Fold 1 WMSE: 2.097520600825856\n",
      "Fold 2 WMSE: 3.5963379626579695\n",
      "Fold 3 WMSE: 3.1037048231979196\n",
      "Fold 4 WMSE: 3.0925891139001895\n",
      "Fold 5 WMSE: 2.48487472587594\n",
      "Average WMSE for Rho 0.2: 2.875005445291575\n",
      "Rho: 0.3\n",
      "Fold 1 WMSE: 2.031541568840903\n",
      "Fold 2 WMSE: 1.6740868740534742\n",
      "Fold 3 WMSE: 5.753672329425185\n",
      "Fold 4 WMSE: 3.060985120789277\n",
      "Fold 5 WMSE: 3.2428425707282225\n",
      "Average WMSE for Rho 0.3: 3.152625692767412\n",
      "Rho: 0.4\n",
      "Fold 1 WMSE: 3.3026735287539255\n",
      "Fold 2 WMSE: 2.1347355120359572\n",
      "Fold 3 WMSE: 2.8404857485693644\n",
      "Fold 4 WMSE: 2.407626074144617\n",
      "Fold 5 WMSE: 3.7992050385697045\n",
      "Average WMSE for Rho 0.4: 2.896945180414714\n",
      "Rho: 0.5\n",
      "Fold 1 WMSE: 4.266774721551104\n",
      "Fold 2 WMSE: 3.0564741543653478\n",
      "Fold 3 WMSE: 2.562473517795221\n",
      "Fold 4 WMSE: 2.856983902163337\n",
      "Fold 5 WMSE: 1.9107352416637913\n",
      "Average WMSE for Rho 0.5: 2.9306883075077605\n",
      "Rho: 0.6\n",
      "Fold 1 WMSE: 2.538203342373666\n",
      "Fold 2 WMSE: 2.92750296436954\n",
      "Fold 3 WMSE: 3.2095060447531067\n",
      "Fold 4 WMSE: 3.5114077215697708\n",
      "Fold 5 WMSE: 1.986098379266785\n",
      "Average WMSE for Rho 0.6: 2.8345436904665737\n",
      "Rho: 0.7\n",
      "Fold 1 WMSE: 3.796010914352304\n",
      "Fold 2 WMSE: 2.867466955594101\n",
      "Fold 3 WMSE: 3.043105407331527\n",
      "Fold 4 WMSE: 3.8627850382826816\n",
      "Fold 5 WMSE: 3.1641306061562595\n",
      "Average WMSE for Rho 0.7: 3.3466997843433743\n",
      "Rho: 0.8\n",
      "Fold 1 WMSE: 1.726248377592259\n",
      "Fold 2 WMSE: 3.117657902169303\n",
      "Fold 3 WMSE: 2.761157851443434\n",
      "Fold 4 WMSE: 3.2863439650267807\n",
      "Fold 5 WMSE: 3.3121513323445306\n",
      "Average WMSE for Rho 0.8: 2.8407118857152613\n",
      "Rho: 0.9\n",
      "Fold 1 WMSE: 2.1405509900541326\n",
      "Fold 2 WMSE: 4.871473365895451\n",
      "Fold 3 WMSE: 3.2882660214927677\n",
      "Fold 4 WMSE: 2.790245672616697\n",
      "Fold 5 WMSE: 3.244091410286539\n",
      "Average WMSE for Rho 0.9: 3.2669254920691175\n",
      "Rho: 1.0\n",
      "Fold 1 WMSE: 4.994508488616726\n",
      "Fold 2 WMSE: 5.134225383499055\n",
      "Fold 3 WMSE: 2.845479165060366\n",
      "Fold 4 WMSE: 3.3995417412748594\n",
      "Fold 5 WMSE: 2.7768404461123355\n",
      "Average WMSE for Rho 1.0: 3.8301190449126685\n",
      "Best Rho: 0.1, Minimum Average WMSE: 2.804719481672591\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy.random as nprand\n",
    "import matplotlib.pyplot as plt\n",
    "from functions.model_training import ICM\n",
    "from functions.weightedMSE import weighted_mean_squared_error\n",
    "\n",
    "seed_value = 1234\n",
    "\n",
    "# Define range of rho values to search over\n",
    "rho_values = np.round(np.arange(0, 1.05, 0.1), 1)\n",
    "\n",
    "# Define number of folds for cross-validation\n",
    "num_folds = 5  # Example: 5-fold cross-validation\n",
    "\n",
    "# Initialize variables to store results\n",
    "cv_rmse_values = []\n",
    "rho_rmse_values = {}  # Dictionary to store RMSE values for each rho\n",
    "min_avg_wmse = float('inf')\n",
    "best_rho = None\n",
    "wmse_per_rho = {}\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "kf = KFold(n_splits=num_folds, shuffle=True)\n",
    "for rho in rho_values:\n",
    "    print(f\"Rho: {rho}\")\n",
    "    avg_wmse = 0\n",
    "    fold_num = 0\n",
    "    wmse_per_fold = []\n",
    "    \n",
    "    for train_index, val_index in kf.split(data_full):\n",
    "        # 5 fold CV for experimental data: split them into 5 folds\n",
    "        train_data, val_data= data_full[train_index], data_full[val_index]\n",
    "        val_data = val_data[val_data[:,0]==1,:]\n",
    "        X_val=val_data[:,1]\n",
    "        T_val=val_data[:,2]\n",
    "        Y_val=val_data[:,3]\n",
    "        w = val_data[:,4]\n",
    "        \n",
    "\n",
    "        m0, m1 = ICM(X_E=train_data[train_data[:,0]==1,1], X_O=train_data[train_data[:,0]==0,1], \n",
    "                     T_E=train_data[train_data[:,0]==1,2], T_O=train_data[train_data[:,0]==0,2], \n",
    "                     Y_E=train_data[train_data[:,0]==1,3], Y_O=train_data[train_data[:,0]==0,3],  \n",
    "                     r=2, ID=1, AD=0, rho=rho)\n",
    "\n",
    "        predY0_exp = m0.predict_noiseless(np.c_[np.vstack(val_data[:,1]), np.ones(val_data[:,1].shape[0]) * 0])\n",
    "        predY1_exp = m1.predict_noiseless(np.c_[np.vstack(val_data[:,1]), np.ones(val_data[:,1].shape[0]) * 0])\n",
    "        predCATE_exp = predY1_exp[0] - predY0_exp[0]\n",
    "        varCATE_exp = predY1_exp[1] + predY0_exp[1]\n",
    "\n",
    "        wmse = weighted_mean_squared_error(weight=w, t = T_val, y_true=Y_val, y_pred0=predY0_exp[0], y_pred1=predY1_exp[0])\n",
    "        avg_wmse += wmse\n",
    "        wmse_per_fold.append(wmse)\n",
    "\n",
    "        print(f\"Fold {fold_num + 1} WMSE: {wmse}\")\n",
    "        fold_num += 1\n",
    "    \n",
    "    avg_wmse /= num_folds\n",
    "    print(f\"Average WMSE for Rho {rho}: {avg_wmse}\")\n",
    "    wmse_per_rho[rho] = wmse_per_fold\n",
    "\n",
    "    # Update min_avg_wmse and best_rho if current avg_wmse is lower\n",
    "    if avg_wmse < min_avg_wmse:\n",
    "        min_avg_wmse = avg_wmse\n",
    "        best_rho = rho\n",
    "\n",
    "# Print the best rho and its corresponding min_avg_wmse\n",
    "print(f\"Best Rho: {best_rho}, Minimum Average WMSE: {min_avg_wmse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sim1_best_rho_df = pd.DataFrame(np.c_[best_rho], columns=['best rho'])\n",
    "sim1_best_rho_df.to_csv('sim1_best_rho.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
