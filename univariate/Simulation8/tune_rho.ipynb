{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.data_simulation import data_simulation8\n",
    "seed_value= 1234\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np \n",
    "np.random.seed(seed_value)\n",
    "data_exp, data_obs = data_simulation8(1000, beta0=-3.0, beta1=-3.0)\n",
    "data_full = np.r_[data_exp, data_obs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model for the probability of participation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "# Logistic regression model for the probability of participating in the trial\n",
    "# S=1 is trial participation and S=0 is non participation \n",
    "logr = linear_model.LogisticRegression()\n",
    "logr.fit(data_full[:,1].reshape(-1,1),data_full[:,0])\n",
    "prob = logr.predict_proba(data_full[:,1].reshape(-1,1))\n",
    "prob_part = prob[:,1]\n",
    "prob_nonpart = prob[:,0]\n",
    "data_full = np.c_[data_full, 1/prob_part]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy.random as nprand\n",
    "import matplotlib.pyplot as plt\n",
    "from functions.model_training import ICM\n",
    "from functions.weightedMSE import weighted_mean_squared_error\n",
    "\n",
    "seed_value = 1234\n",
    "\n",
    "# Define range of rho values to search over\n",
    "rho_values = np.round(np.arange(0, 1.05, 0.1), 1)\n",
    "\n",
    "# Define number of folds for cross-validation\n",
    "num_folds = 5  # Example: 5-fold cross-validation\n",
    "\n",
    "# Initialize variables to store results\n",
    "cv_rmse_values = []\n",
    "rho_rmse_values = {}  # Dictionary to store RMSE values for each rho\n",
    "min_avg_wmse = float('inf')\n",
    "best_rho = None\n",
    "wmse_per_rho = {}\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "kf = KFold(n_splits=num_folds, shuffle=True)\n",
    "for rho in rho_values:\n",
    "    \n",
    "    print(f\"Rho: {rho}\")\n",
    "    avg_wmse = 0\n",
    "    fold_num = 0\n",
    "    wmse_per_fold = []\n",
    "    \n",
    "    for train_index, val_index in kf.split(data_full):\n",
    "        # 5 fold CV for experimental data: split them into 5 folds\n",
    "        train_data, val_data= data_full[train_index], data_full[val_index]\n",
    "        val_data = val_data[val_data[:,0]==1,:]\n",
    "        X_val=val_data[:,1]\n",
    "        T_val=val_data[:,2]\n",
    "        Y_val=val_data[:,3]\n",
    "        w = val_data[:,4]\n",
    "        \n",
    "\n",
    "        m0, m1 = ICM(X_E=train_data[train_data[:,0]==1,1], X_O=train_data[train_data[:,0]==0,1], \n",
    "                     T_E=train_data[train_data[:,0]==1,2], T_O=train_data[train_data[:,0]==0,2], \n",
    "                     Y_E=train_data[train_data[:,0]==1,3], Y_O=train_data[train_data[:,0]==0,3],  \n",
    "                     r=2, ID=1, AD=0, rho=rho)\n",
    "\n",
    "        predY0_exp = m0.predict_noiseless(np.c_[np.vstack(val_data[:,1]), np.ones(val_data[:,1].shape[0]) * 0])\n",
    "        predY1_exp = m1.predict_noiseless(np.c_[np.vstack(val_data[:,1]), np.ones(val_data[:,1].shape[0]) * 0])\n",
    "        predCATE_exp = predY1_exp[0] - predY0_exp[0]\n",
    "        varCATE_exp = predY1_exp[1] + predY0_exp[1]\n",
    "\n",
    "        wmse = weighted_mean_squared_error(weight=w, t = T_val, y_true=Y_val, y_pred0=predY0_exp[0], y_pred1=predY1_exp[0])\n",
    "        avg_wmse += wmse\n",
    "        wmse_per_fold.append(wmse)\n",
    "\n",
    "        print(f\"Fold {fold_num + 1} WMSE: {wmse}\")\n",
    "        fold_num += 1\n",
    "    \n",
    "    avg_wmse /= num_folds\n",
    "    print(f\"Average WMSE for Rho {rho}: {avg_wmse}\")\n",
    "    wmse_per_rho[rho] = wmse_per_fold\n",
    "\n",
    "    # Update min_avg_wmse and best_rho if current avg_wmse is lower\n",
    "    if avg_wmse < min_avg_wmse:\n",
    "        min_avg_wmse = avg_wmse\n",
    "        best_rho = rho\n",
    "\n",
    "# Print the best rho and its corresponding min_avg_wmse\n",
    "print(f\"Best Rho: {best_rho}, Minimum Average WMSE: {min_avg_wmse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sim8_best_rho_df = pd.DataFrame(np.c_[best_rho], columns=['best rho'])\n",
    "sim8_best_rho_df.to_csv('sim8_best_rho.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
